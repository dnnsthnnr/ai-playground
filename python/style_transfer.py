import os
import numpy as np
import time

import tensorflow as tf
from PIL import Image
from keras import backend as K
from keras.applications import VGG16
from keras.applications.vgg16 import WEIGHTS_PATH_NO_TOP
from keras.engine import Layer
from keras.layers import Conv2D, Input, Activation, BatchNormalization, Conv2DTranspose, add, concatenate
from keras.models import Model
from keras.optimizers import Adam
from keras.preprocessing.image import ImageDataGenerator
from keras.regularizers import Regularizer
from keras.utils import get_file
from scipy.misc import imsave
from scipy.misc.pilutil import imshow

from python import utils
from python.utils import ImageNormalize, Denormalize


def dummy_loss(y_true, y_pred):
    return K.variable(0.0)


def gram_matrix(x):
    assert K.ndim(x) == 3
    if K.image_dim_ordering() == 'th':
        features = K.batch_flatten(x)
    else:
        features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))

    shape = K.shape(x)

    C, W, H = (shape[0], shape[1], shape[2])

    cf = K.reshape(features, (C, -1))
    gram = K.dot(cf, K.transpose(cf)) / K.cast(C * W * H, dtype='float32')

    return gram


class StyleReconstructionRegularizer(Regularizer):
    """ Johnson et al 2015 https://arxiv.org/abs/1603.08155 """

    def __init__(self, style_feature_target, weight=1.0):
        self.style_feature_target = style_feature_target
        self.weight = weight
        self.uses_learning_phase = False
        super(StyleReconstructionRegularizer, self).__init__()

        self.style_gram = gram_matrix(style_feature_target)

    def __call__(self, x):
        output = x.output[0]  # Generated by network
        loss = self.weight * K.sum(K.mean(K.square((self.style_gram - gram_matrix(output)))))

        return loss


class FeatureReconstructionRegularizer(Regularizer):
    """ Johnson et al 2015 https://arxiv.org/abs/1603.08155 """

    def __init__(self, weight=1.0):
        self.weight = weight
        self.uses_learning_phase = False
        super(FeatureReconstructionRegularizer, self).__init__()

    def __call__(self, x):
        generated = x.output[0]  # Generated by network features
        content = x.output[1]  # True X input features

        loss = self.weight * K.sum(K.mean(K.square(content - generated)))
        return loss


class TVRegularizer(Regularizer):
    """ Enforces smoothness in image output. """

    def __init__(self, weight=1.0):
        self.weight = weight
        self.uses_learning_phase = False
        super(TVRegularizer, self).__init__()

    def __call__(self, x):
        assert K.ndim(x.output) == 4
        x_out = x.output

        shape = K.shape(x_out)
        img_width, img_height, channel = (shape[1], shape[2], shape[3])
        size = img_width * img_height * channel
        if K.image_dim_ordering() == 'th':
            a = K.square(x_out[:, :, :img_width - 1, :img_height - 1] - x_out[:, :, 1:, :img_height - 1])
            b = K.square(x_out[:, :, :img_width - 1, :img_height - 1] - x_out[:, :, :img_width - 1, 1:])
        else:
            a = K.square(x_out[:, :img_width - 1, :img_height - 1, :] - x_out[:, 1:, :img_height - 1, :])
            b = K.square(x_out[:, :img_width - 1, :img_height - 1, :] - x_out[:, :img_width - 1, 1:, :])
        loss = self.weight * K.sum(K.pow(a + b, 1.25))
        return loss




class StyleTransfer:
    model = None
    style_name = ""
    style_img = None
    style_layers = ['block1_conv2', 'block2_conv2', 'block3_conv3', 'block4_conv3']
    content_layer = 'block3_conv3'
    img_width = 256
    img_height = 256
    style_weight = 4
    tv_weight = 1e-5
    content_weight = 1
    weight_path = 'style_transfer_{}.hdf5'
    data_dir = '../data/MS COCO/2014/images/'
    train_data, val_data = (None, None)

    def __init__(self, style):
        self.style_name = style
        style_img = Image.open(os.path.join("../ai-playground/src/assets/styles", style + '.jpg'))
        style_img = style_img.convert('RGB')
        style_img = utils.crop_to_square(style_img)
        self.style_img = np.asarray(style_img.resize((self.img_width, self.img_height))).astype(K.floatx())
        self.style_img = self.style_img.reshape((1,) + self.style_img.shape)
        self.weight_path = os.path.join(utils.MODEL_DIR, self.weight_path.format(style))

        # files = os.listdir(self.data_dir)
        # split = int(0.2 * len(files))
        # self.val_data = files[:split]
        # self.train_data = files[split:]
        #
        # print("{} train samples, {} validations samples".format(len(self.train_data), len(self.val_data)))

    def build_model(self):
        img_in = Input((self.img_width, self.img_height, 3))
        norm = ImageNormalize()(img_in)
        conv1 = self.conv_layer(norm, 32, 9, 1)
        conv2 = self.conv_layer(conv1, 64, 3, 2)
        conv3 = self.conv_layer(conv2, 128, 3, 2)
        resid1 = self.residual_block(conv3)
        resid2 = self.residual_block(resid1)
        resid3 = self.residual_block(resid2)
        resid4 = self.residual_block(resid3)
        resid5 = self.residual_block(resid4)
        conv_t1 = self.conv_transpose_layer(resid5, 64, 3, 2)
        conv_t2 = self.conv_transpose_layer(conv_t1, 32, 3, 2)
        conv_t3 = self.conv_layer(conv_t2, 3, 9, 1, relu=False)
        out = Activation('tanh')(conv_t3)
        out = Denormalize()(out)

        self.model = Model(img_in, out)
        if os.path.exists(self.weight_path):
            self.model.load_weights(self.weight_path, by_name=True)
        self.model.summary()

    def loss_net(self, x_in, true_x_in):
        x = concatenate([x_in, true_x_in], axis=0)
        vgg = VGG16(input_tensor=x, include_top=False, weights=None)
        vgg.load_weights(get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',
                                  WEIGHTS_PATH_NO_TOP,
                                  cache_subdir='models'), by_name=True)

        vgg_out_dict = dict([(layer.name, layer.output) for layer in vgg.layers[-18:]])
        vgg_layers = dict([(layer.name, layer) for layer in vgg.layers[-18:]])

        # add style loss
        style_layer_outputs = []
        for layer in self.style_layers:
            style_layer_outputs.append(vgg_out_dict[layer])

        vgg_style_func = K.function([vgg.layers[-18].input], style_layer_outputs)
        style_features = vgg_style_func([self.style_img])
        for i, layer_name in enumerate(self.style_layers):
            layer = vgg_layers[layer_name]
            style_loss = StyleReconstructionRegularizer(style_feature_target=K.variable(style_features[i][0]),
                                                        weight=self.style_weight)(layer)
            layer.add_loss(style_loss)

        # add content loss
        content_layer = vgg_layers[self.content_layer]
        content_loss = FeatureReconstructionRegularizer(self.content_weight)(content_layer)
        content_layer.add_loss(content_loss)

        # add total variation loss
        layer = vgg.layers[-20]
        tv_loss = TVRegularizer(self.tv_weight)(layer)
        layer.add_loss(tv_loss)

        # freeze vgg layers
        for l in vgg.layers[-19:]:
            l.trainable = False

        vgg.summary()

        return vgg

    def conv_layer(self, net, num_filter, filter_size, strides, relu=True):
        net = Conv2D(num_filter, filter_size, strides=(strides, strides), padding='same')(net)
        net = BatchNormalization()(net)
        if relu:
            net = Activation('relu')(net)
        return net

    def conv_transpose_layer(self, net, num_filters, filter_size, strides):
        net = Conv2DTranspose(num_filters, filter_size, strides=(strides, strides), padding='same', use_bias=False)(net)
        return self.conv_layer(net, num_filters, filter_size, 1)

    def residual_block(self, net, filter_size=3):
        conv1 = self.conv_layer(net, 128, filter_size, 1)
        conv2 = self.conv_layer(conv1, 128, filter_size, 1, relu=False)
        return add([net, conv2])

    def train(self, epochs, batch_size=1):
        self.build_model()
        loss_net = self.loss_net(self.model.output, self.model.input)
        loss_net.compile(optimizer=Adam(), loss=dummy_loss)
        dummy_y = np.zeros((batch_size, self.img_width, self.img_height, 3))
        data_gen = ImageDataGenerator()
        total_batches = int(len(os.listdir(self.data_dir)) / batch_size)

        for e in range(epochs):
            print("\nEpoch: {}/{}".format(e + 1, epochs))

            i = 0
            t1 = time.time()
            for x in data_gen.flow_from_directory(self.data_dir, target_size=(self.img_width, self.img_height),
                                                  class_mode=None, batch_size=batch_size, shuffle=False, classes=['']):
                if i > total_batches:
                    break
                hist = loss_net.train_on_batch(x, dummy_y)

                if i % 1000 == 0:
                    print("\n", hist, time.time() - t1)
                    t1 = time.time()
                    self.model.save_weights(self.weight_path)

                if i % 10000 == 0:
                    print("Saving progress image")
                    self.plot(save=True, name="{}_e{}_i{}".format(self.style_name, e + 1, i))

                utils.progress_bar(i, total_batches)
                i += 1

            print("\n Saving model")
            self.model.save_weights(self.weight_path)

    def plot(self, save=False, name=None):
        example_image = "COCO_train2014_000000000077.jpg"
        if self.model is None:
            self.build_model()

        img = Image.open(os.path.join(self.data_dir, example_image))
        img = utils.crop_to_square(img)
        img = img.resize((self.img_width, self.img_height))
        x = np.asarray(img).astype(K.floatx())
        x = x.reshape((1, self.img_width, self.img_height, 3))

        y = self.model.predict(x)[0]

        if not save:
            imshow(y)
        else:
            imsave(os.path.join("..", "generated", name + ".png"), y)

    def export_to_frontend(self):
        if self.model is None:
            self.build_model()
        utils.export_keras_for_deeplearn("style_transfer/" + self.style_name)


if __name__ == "__main__":
    config = tf.ConfigProto()
    config.gpu_options.per_process_gpu_memory_fraction = 0.75
    K.set_session(tf.Session(config=config))
    st = StyleTransfer('udnie')
    #st.export_to_frontend()
    st.train(1)
    # st.plot()
